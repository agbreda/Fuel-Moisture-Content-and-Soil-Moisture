{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import stats\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make one empty list for each soil moisture product\n",
    "\n",
    "products = ['AWRAL.csv',\n",
    " 'SMOS_LMEB_A.csv',\n",
    " 'AMSR2_LPRM_D.csv',\n",
    " 'ASCAT_TUW_D.csv',\n",
    " 'SMOS_LPRM_A.csv',\n",
    " 'WaterDyn.csv',\n",
    " 'MSDI.csv',\n",
    " 'API.csv',\n",
    " 'KBDI.csv',\n",
    " 'AMSR2_JAXA_A.csv',\n",
    " 'CABLE.csv']\n",
    "\n",
    "#we will keep them in this order\n",
    "\n",
    "aux = []\n",
    "f=open('multi_products/SWEEP.v1.0/' + products[0],'r',encoding=\"ISO-8859-1\")\n",
    "#reading the first product file\n",
    "\n",
    "for line in f:\n",
    "    if line[:9]== 'Site name':\n",
    "        x=line.split(',')\n",
    "        aux.append(x[1:]) \n",
    "    if line[:3] == 'Lat':\n",
    "        x=line.split(',')\n",
    "        aux.append(x[1:])\n",
    "    elif line[:3]=='Lon':\n",
    "        x=line.split(',')\n",
    "        aux.append(x[1:])\n",
    "        \n",
    "sites = []\n",
    "for i in range(len(aux[0])):\n",
    "    try: \n",
    "        lat = float(aux[0][i][0:-1]) \n",
    "    except ValueError:\n",
    "        lat = float(aux[0][i][0:-2])\n",
    "    try: \n",
    "        lon = float(aux[1][i][0:-1]) \n",
    "    except ValueError:\n",
    "        lon = float(aux[1][i][0:-2])\n",
    "    if aux[2][i][0:3] == 'Wea':\n",
    "        aux[2][i] = aux[2][i][0:-1]\n",
    "    sites.append([aux[2][i], -1*lat, lon])\n",
    "        \n",
    "#Sites contains long lat for each site in a nested list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWRAL.csv\n",
      "SMOS_LMEB_A.csv\n",
      "AMSR2_LPRM_D.csv\n",
      "ASCAT_TUW_D.csv\n",
      "SMOS_LPRM_A.csv\n",
      "WaterDyn.csv\n",
      "MSDI.csv\n",
      "API.csv\n",
      "KBDI.csv\n",
      "AMSR2_JAXA_A.csv\n",
      "CABLE.csv\n"
     ]
    }
   ],
   "source": [
    "# loop through products to get the data for each day for each site\n",
    "\n",
    "data =[]\n",
    "\n",
    "for name in products:\n",
    "    dse = []\n",
    "    sm = []\n",
    "    f=open('multi_products/SWEEP.v1.0/' + name,'r',encoding=\"ISO-8859-1\")\n",
    "    \n",
    "    for line in f:\n",
    "        try: \n",
    "            line = line.split(',')\n",
    "            y, m, d = int(line[0][0:4]), int(line[0][4:6]), int(line[0][6:8])\n",
    "            dt = datetime(y, m, d) - datetime(1900, 1, 1)\n",
    "            dse.append(dt.days)\n",
    "            sm.append(list(map(float, line[1:])))\n",
    "        except: \n",
    "            pass \n",
    "    aux = pd.DataFrame(sm)\n",
    "    \n",
    "    #aux.replace({-9999.0:np.nan}, inplace = True)\n",
    "    \n",
    "    for i in range(aux.shape[0]):\n",
    "        for j in range(aux.shape[1]):\n",
    "            if aux[j][i] < -9000:\n",
    "                aux[j][i] = np.nan\n",
    "    \n",
    "    aux.rename(index = dict([(i, dse[i]) for i in range(len(dse))]), inplace = True)\n",
    "    data.append(aux)\n",
    "    \n",
    "    print(name)\n",
    "    \n",
    "with open('multi_products/products_data.pkl','wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "    \n",
    "    \n",
    "#Missing data? Replace -9999.0's with Nan\n",
    "\n",
    "#To locate data by index use loc\n",
    "#df.loc[['row index name']][column name/index]\n",
    "\n",
    "#in pandas, the first [ ] denotes column, the second row\n",
    "# as opposed to python where the first [ ] is row, second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/oe9/software/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: Warning: converting a masked element to nan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "57.25722122192383\n"
     ]
    }
   ],
   "source": [
    "# Want to find corresponding FMC values for those dates and sites\n",
    "\n",
    "fmct, fmc = [], [] # for time and data respectively\n",
    "\n",
    "for year in range(2001,2015):\n",
    "    url_fmc = 'http://dapds00.nci.org.au/thredds/dodsC/ub8/au/FMC/c6/mosaics/fmc_c6_'+ str('%i' % year) + '.nc'\n",
    "    fmc_data = Dataset(url_fmc, 'r')\n",
    "    \n",
    "    lat_fmc = fmc_data['latitude'][:]\n",
    "    lon_fmc = fmc_data['longitude'][:]\n",
    "    time = fmc_data['time'][:]\n",
    "        \n",
    "#computing the 3 x 3 FMC gridded average around the given sites\n",
    "    aa, bb = [], []\n",
    "    for s in sites:\n",
    "        a = np.where((lat_fmc < s[1]+0.00251) & (lat_fmc > s[1]-0.00251))\n",
    "        b = np.where((lon_fmc < s[2]+0.00251) & (lon_fmc > s[2]-0.00251))\n",
    "        #print(a,b, lat_fmc[0], lat_fmc[-1], s[1])\n",
    "        aa.append(a[0][0])\n",
    "        bb.append(b[0][0])       \n",
    "    \n",
    "    for i in range (time.size):\n",
    "        x = datetime(1970,1,1) + timedelta(seconds = int(time[i]))\n",
    "        x = x-datetime(1900,1,1)\n",
    "        fmct.append(x.days)\n",
    "        fmc.append(np.zeros(len(sites), dtype=float) * np.nan)\n",
    "        \n",
    "        for s in range(len(sites)):\n",
    "            v1 = np.mean(fmc_data['fmc_mean'][i,aa[s]-1:aa[s]+2,bb[s]-1:bb[s]+2])\n",
    "            fmc[-1][s] = v1\n",
    "    \n",
    "    print(year)\n",
    "\n",
    "fmc = pd.DataFrame(fmc)\n",
    "print(fmc[0][0])\n",
    "\n",
    "with open('multi_products/fmc_data2.pkl', 'wb') as f:\n",
    "    pickle.dump([fmct, fmc], f)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('multi_products/fmc_data2.pkl','rb') as f:\n",
    "    fmct, fmc = pickle.load(f)\n",
    "\n",
    "with open('multi_products/products_data.pkl','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "# from best import fit_best\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def linear(x, a, b):\n",
    "    return a * x + b\n",
    "\n",
    "#def glf(x, A, K, C, Q, B, ni):\n",
    "#    return A + (K - A) / ((C + Q * np.exp(-B * x)) ** (1./ni))\n",
    "\n",
    "def glf(x, A, K, B, ni):\n",
    "    return A + (K - A) / (np.exp(-B * x) ** (1./ni))\n",
    "\n",
    "def exponencial(x, a, b, c):\n",
    "    return a + b * np.exp(c*x)\n",
    "\n",
    "def powerlaw(x, a, b, c):\n",
    "    return a + b * (x**c)\n",
    "\n",
    "def fit_best(xdata, ydata):\n",
    "    \"\"\" Fits many function types to the provided x,y datasets and return the best based on rÂ² value.\n",
    "    The functions are:\n",
    "        (1) linear regression;\n",
    "        (2) generalised logistic function;\n",
    "        (3) an exponencial function and;\n",
    "        (4) power-law function\n",
    "    \"\"\"\n",
    "    bestmodel = 1\n",
    "    \n",
    "    foundfit = False\n",
    "    \n",
    "    # Fitting the linear model first\n",
    "    try:\n",
    "        param_lin, pcov = curve_fit(linear, xdata, ydata, maxfev=10000)\n",
    "        yf = linear(xdata, *param_lin)\n",
    "        r, p = stats.pearsonr(ydata, yf)\n",
    "        r2max = r ** 2\n",
    "        foundfit = True\n",
    "    except RuntimeError:\n",
    "        r2max = 0\n",
    "    \n",
    "    \n",
    "    # Fitting the generalised logistic function\n",
    "    try:\n",
    "        param_glf, pcov = curve_fit(glf, xdata, ydata, maxfev=10000)\n",
    "        yf = glf(xdata, *param_glf)\n",
    "        r, p = stats.pearsonr(ydata, yf)\n",
    "        r2 = r ** 2\n",
    "        foundfit = True\n",
    "\n",
    "        if r2 > r2max:\n",
    "            bestmodel = 2\n",
    "            r2max = r2\n",
    "            \n",
    "    except RuntimeError:\n",
    "        r2max = 0\n",
    "    \n",
    "    # Fitting the exponencial function\n",
    "    try:\n",
    "        param_exp, pcov = curve_fit(exponencial, xdata, ydata, maxfev=10000)\n",
    "        yf = exponencial(xdata, *param_exp)\n",
    "        r, p = stats.pearsonr(ydata, yf)\n",
    "        r2 = r ** 2\n",
    "        foundfit = True\n",
    "\n",
    "        if r2 > r2max:\n",
    "            bestmodel = 3\n",
    "            r2max = r2\n",
    "            \n",
    "    except RuntimeError:\n",
    "        r2max = 0\n",
    "    \n",
    "    # Fitting the power-law function\n",
    "    try:\n",
    "        param_law, pcov = curve_fit(powerlaw, xdata, ydata, maxfev=10000)\n",
    "        yf = powerlaw(xdata, *param_law)\n",
    "        r, p = stats.pearsonr(ydata, yf)\n",
    "        r2 = r ** 2\n",
    "        foundfit = True\n",
    "\n",
    "        if r2 > r2max:\n",
    "            bestmodel = 4\n",
    "            r2max = r2\n",
    "    \n",
    "    except RuntimeError:\n",
    "        r2max = 0\n",
    "\n",
    "    if foundfit:\n",
    "        \n",
    "        # Use the best fit to create a sample of 100 x,y pairs of model data\n",
    "        xi = np.linspace(np.min(xdata), np.max(xdata), 100)\n",
    "\n",
    "        if bestmodel == 1:\n",
    "            yi = linear(xi, *param_lin)\n",
    "        elif bestmodel == 2:\n",
    "            yi = glf(xi, *param_glf)\n",
    "        elif bestmodel == 3:\n",
    "            yi = exponencial(xi, *param_exp)\n",
    "        else:\n",
    "            yi = powerlaw(xi, *param_law)\n",
    "\n",
    "        return xi, yi, r2max\n",
    "    \n",
    "    else:\n",
    "        return xi, xi*np.nan, r2max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/oe9/software/miniconda3/lib/python3.6/site-packages/scipy/optimize/minpack.py:794: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/g/data/oe9/software/miniconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3010: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    }
   ],
   "source": [
    "# creating one figure per site with subplots of each product\n",
    "NS = range(len(sites))\n",
    "NP = range(len(products))\n",
    "table = np.zeros((len(sites), len(products))) - 1\n",
    "\n",
    "for si in NS:\n",
    "    fig, axes = plt.subplots(nrows=2,ncols=6, figsize=(20,7))\n",
    "    \n",
    "    for j, ax in enumerate(axes.flatten()):\n",
    "        \n",
    "        if j == 11:\n",
    "            continue\n",
    "        \n",
    "        # scatter plot\n",
    "        ax.scatter(data[j][si][fmct], fmc[si], label='_nolegend_')\n",
    "        ax.set_title(products[j][:-4])\n",
    "        \n",
    "        # gathering only real values (removing nan)\n",
    "        Xlr, Ylr = data[j][si][fmct], fmc[si]\n",
    "        mask = np.isfinite([Xlr, Ylr]).all(axis=0)\n",
    "        \n",
    "#         # computing linear regression\n",
    "#         slope, intercept, r_value, p_value, std_err = stats.linregress(Xlr[mask], Ylr[mask])\n",
    "#         strlin = str('r$^2$ = %f' %(r_value**2))\n",
    "#         table[si,j] = r_value**2\n",
    "#         minx, maxx = np.min(Xlr[mask]), np.max(Xlr[mask])\n",
    "#         miny, maxy = slope*minx + intercept, slope*maxx + intercept\n",
    "#         ax.plot([minx, maxx], [miny,maxy], 'k-', label = strlin)\n",
    "        \n",
    "        # fitting the best model\n",
    "        xm, ym, r2 = fit_best(Xlr[mask], Ylr[mask])\n",
    "        table[si,j] = r2\n",
    "        strlin = str('r$^2$ = %f' % r2)\n",
    "        ax.plot(xm, ym, 'k-', lw = 2, label = strlin)\n",
    "        \n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        \n",
    "    fig.suptitle(sites[si][0])\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    plt.savefig(str('images/multproducts_%2.2i.png' % si))\n",
    "    plt.close(fig)\n",
    "\n",
    "table = pd.DataFrame(table)\n",
    "table.rename(index = dict([(i, sites[i][0]) for i in NS]), inplace = True)\n",
    "table.columns = [x[:-4] for x in products]\n",
    "table.to_csv('multi_products/multi_daily_best_r2.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWRAL.csv\n",
      "SMOS_LMEB_A.csv\n",
      "AMSR2_LPRM_D.csv\n",
      "ASCAT_TUW_D.csv\n",
      "SMOS_LPRM_A.csv\n",
      "WaterDyn.csv\n",
      "MSDI.csv\n",
      "API.csv\n",
      "KBDI.csv\n",
      "AMSR2_JAXA_A.csv\n",
      "CABLE.csv\n"
     ]
    }
   ],
   "source": [
    "for p in NP:\n",
    "    csv = open(str('categ/%s' % products[p]), 'w')\n",
    "    for si in NS:\n",
    "        csv.write(',%s' % sites[si][0])\n",
    "    csv.write('\\n')\n",
    "    for t in fmct:\n",
    "        csv.write('%i' % t)\n",
    "        for si in NS:\n",
    "            csv.write(',%f' % data[p][si][t])\n",
    "        csv.write('\\n')\n",
    "    csv.close()\n",
    "    print(products[p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = open('categ/FMC.csv','w')\n",
    "for si in NS:\n",
    "    csv.write(',%s' % sites[si][0])\n",
    "csv.write('\\n')\n",
    "for t in range(len(fmct)):\n",
    "    csv.write('%i' % fmct[t])\n",
    "    for i in NS:\n",
    "        csv.write(',%f' % fmc[i][t])\n",
    "    csv.write('\\n')\n",
    "csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/oe9/software/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:35: RuntimeWarning: Mean of empty slice\n",
      "/g/data/oe9/software/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "#Create a new monthly correlation with the data that we did the daily time step for FMC and SM\n",
    "#Our data in the daily products is in a list\n",
    "\n",
    "#Create a empty list which we will put the monthly data\n",
    "mdata =[]\n",
    "\n",
    "#Convert the first day into date time and the last one to check the years there\n",
    "fmct = np.array(fmct, dtype=int)\n",
    "start = datetime(1900, 1, 1) + timedelta(days = int(fmct[0]))\n",
    "end =   datetime(1900, 1, 1) + timedelta(days = int(fmct[-1]))\n",
    "#We need to do a for loop to cycle through the years and another to cycle through the month\n",
    "# each product will have a dateframe\n",
    "# the last product will be the fmc column\n",
    "#function separate by comma and list and array semi colon separator\n",
    "#tn is day in the next month but complicated because monthe have different days\n",
    "for s in range(len(sites)):\n",
    "    sdata, months = [], []\n",
    "#for p in range(len(products)+1):\n",
    "    for y in range(start.year, end.year+1):\n",
    "        for m in range(1,13):\n",
    "            #creating the boundaries in time within the month for the data frame\n",
    "            t0 = datetime(y, m, 1) - datetime(1900, 1, 1)\n",
    "            t0 = t0.days\n",
    "            tn = datetime(y,m,1) + timedelta(days=40) \n",
    "            tn = datetime(tn.year, tn.month, 1)- datetime(1900, 1, 1)\n",
    "            tn = tn.days\n",
    "            w = np.where((fmct >= t0) & (fmct < tn))[0]#returns a tuple with a list\n",
    "            \n",
    "            #collect the average betweeen t0 an tn and create average and store it\n",
    "            aux =[]\n",
    "            g = np.arange(t0,tn)\n",
    "            for p in range(len(products)):\n",
    "                q = data[p][s][g]\n",
    "                #here we compute the mean\n",
    "                aux.append(np.nanmean(q))\n",
    "            q = np.nanmean(fmc[s][w])\n",
    "            aux.append(q)\n",
    "            sdata.append(aux)\n",
    "            #created a variiable datetime and called the method strftime\n",
    "            #to create a string from the datetime\n",
    "            argument = datetime(y,m,1).strftime('%Y-%m')\n",
    "            months.append(argument)\n",
    "                          \n",
    "           #print(s,y,m,months)\n",
    "\n",
    "    #sdata is the dataframe for just one site\n",
    "    \n",
    "    names = [products[i][0:-4] for i in range(len(products))]\n",
    "    sdata = pd.DataFrame(sdata, columns = names +['FMC'], index = months)\n",
    "    #print(sdata)\n",
    "    \n",
    "    mdata.append(sdata)\n",
    "\n",
    "#mdata has all the data for all the sites\n",
    "#print(mdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots of mdata\n",
    "\n",
    "# creating one figure per site with subplots of each product\n",
    "NS = range(len(sites))\n",
    "NP = range(len(products))\n",
    "table = np.zeros((len(sites), len(products))) - 1\n",
    "\n",
    "for si in NS:\n",
    "    fig, axes = plt.subplots(nrows=2,ncols=6, figsize=(20,7))\n",
    "    \n",
    "    for j, ax in enumerate(axes.flatten()):\n",
    "        \n",
    "        if j == 11:\n",
    "            continue\n",
    "        \n",
    "        # scatter plot\n",
    "        ax.scatter(mdata[si][names[j]], mdata[si]['FMC'], label='_nolegend_')\n",
    "        ax.set_title(names[j])\n",
    "        \n",
    "        # gathering only real values (removing nan)\n",
    "        Xlr, Ylr = mdata[si][names[j]], mdata[si]['FMC']\n",
    "        mask = np.isfinite([Xlr, Ylr]).all(axis=0)\n",
    "        \n",
    "#         # computing linear regression\n",
    "#         slope, intercept, r_value, p_value, std_err = stats.linregress(Xlr[mask], Ylr[mask])\n",
    "#         strlin = str('r$^2$ = %f' %(r_value**2))\n",
    "#         table[si,j] = r_value**2\n",
    "#         minx, maxx = np.min(Xlr[mask]), np.max(Xlr[mask])\n",
    "#         miny, maxy = slope*minx + intercept, slope*maxx + intercept\n",
    "#         ax.plot([minx, maxx], [miny,maxy], 'k-', label = strlin)\n",
    "        \n",
    "        # fitting the best model\n",
    "        xm, ym, r2 = fit_best(Xlr[mask], Ylr[mask])\n",
    "        table[si,j] = r2\n",
    "        strlin = str('r$^2$ = %f' % r2)\n",
    "        ax.plot(xm, ym, 'k-', lw = 2, label = strlin)\n",
    "        \n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        \n",
    "    fig.suptitle(sites[si][0])\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    plt.savefig(str('multi_products/monthly_best/monthlymean_%2.2i.png' % si))\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "table = pd.DataFrame(table)\n",
    "table.rename(index = dict([(i, sites[i][0]) for i in NS]), inplace = True)\n",
    "table.columns = [x[:-4] for x in products]\n",
    "table.to_csv('multi_products/multi_month_best_r2.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
